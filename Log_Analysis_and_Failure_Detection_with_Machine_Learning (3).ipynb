{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Log Analysis and Failure Detection with Machine Learning",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lo0ivBaGl7Hu",
        "outputId": "313cc641-3f34-467e-cd79-f74823e7ea79"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('Zookeeper.log', sep=\"INFO\",header=None,error_bad_lines=False)\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                0                                                  1\n",
            "0      2015-07-29 17:41:41,536 -     [main:QuorumPeerConfig@101] - Reading config...\n",
            "1      2015-07-29 17:41:41,544 -     [main:QuorumPeerConfig@334] - Defaulting to ...\n",
            "2      2015-07-29 17:41:41,555 -     [main:DatadirCleanupManager@78] - autopurge....\n",
            "3      2015-07-29 17:41:41,555 -     [main:DatadirCleanupManager@79] - autopurge....\n",
            "4      2015-07-29 17:41:41,557 -     [main:DatadirCleanupManager@101] - Purge tas...\n",
            "...                           ...                                                ...\n",
            "74375  2015-08-25 11:26:27,898 -     [WorkerReceiver[myid=3]:FastLeaderElection@5...\n",
            "74376  2015-08-25 11:26:28,138 -     [LearnerHandler-/10.10.34.12:38330:LearnerHa...\n",
            "74377  2015-08-25 11:26:28,159 -     [LearnerHandler-/10.10.34.12:38330:LearnerHa...\n",
            "74378  2015-08-25 11:26:28,159 -     [LearnerHandler-/10.10.34.12:38330:LearnerHa...\n",
            "74379  2015-08-25 11:26:28,159 -     [LearnerHandler-/10.10.34.12:38330:LearnerHa...\n",
            "\n",
            "[74380 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "O9sM-H2bmCJe",
        "outputId": "f46a0a75-8def-4678-c93c-b434d8ae849b"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-07-29 17:41:41,536 -</td>\n",
              "      <td>[main:QuorumPeerConfig@101] - Reading config...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-07-29 17:41:41,544 -</td>\n",
              "      <td>[main:QuorumPeerConfig@334] - Defaulting to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015-07-29 17:41:41,555 -</td>\n",
              "      <td>[main:DatadirCleanupManager@78] - autopurge....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015-07-29 17:41:41,555 -</td>\n",
              "      <td>[main:DatadirCleanupManager@79] - autopurge....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015-07-29 17:41:41,557 -</td>\n",
              "      <td>[main:DatadirCleanupManager@101] - Purge tas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74375</th>\n",
              "      <td>2015-08-25 11:26:27,898 -</td>\n",
              "      <td>[WorkerReceiver[myid=3]:FastLeaderElection@5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74376</th>\n",
              "      <td>2015-08-25 11:26:28,138 -</td>\n",
              "      <td>[LearnerHandler-/10.10.34.12:38330:LearnerHa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74377</th>\n",
              "      <td>2015-08-25 11:26:28,159 -</td>\n",
              "      <td>[LearnerHandler-/10.10.34.12:38330:LearnerHa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74378</th>\n",
              "      <td>2015-08-25 11:26:28,159 -</td>\n",
              "      <td>[LearnerHandler-/10.10.34.12:38330:LearnerHa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74379</th>\n",
              "      <td>2015-08-25 11:26:28,159 -</td>\n",
              "      <td>[LearnerHandler-/10.10.34.12:38330:LearnerHa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>74380 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                0                                                  1\n",
              "0      2015-07-29 17:41:41,536 -     [main:QuorumPeerConfig@101] - Reading config...\n",
              "1      2015-07-29 17:41:41,544 -     [main:QuorumPeerConfig@334] - Defaulting to ...\n",
              "2      2015-07-29 17:41:41,555 -     [main:DatadirCleanupManager@78] - autopurge....\n",
              "3      2015-07-29 17:41:41,555 -     [main:DatadirCleanupManager@79] - autopurge....\n",
              "4      2015-07-29 17:41:41,557 -     [main:DatadirCleanupManager@101] - Purge tas...\n",
              "...                           ...                                                ...\n",
              "74375  2015-08-25 11:26:27,898 -     [WorkerReceiver[myid=3]:FastLeaderElection@5...\n",
              "74376  2015-08-25 11:26:28,138 -     [LearnerHandler-/10.10.34.12:38330:LearnerHa...\n",
              "74377  2015-08-25 11:26:28,159 -     [LearnerHandler-/10.10.34.12:38330:LearnerHa...\n",
              "74378  2015-08-25 11:26:28,159 -     [LearnerHandler-/10.10.34.12:38330:LearnerHa...\n",
              "74379  2015-08-25 11:26:28,159 -     [LearnerHandler-/10.10.34.12:38330:LearnerHa...\n",
              "\n",
              "[74380 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0FvTS_tmCtt"
      },
      "source": [
        "df.columns=['Date&Time','Message']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "vGMk8XG2mE6O",
        "outputId": "a2238a3d-4fdb-4de4-8511-518e353dc913"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date&amp;Time</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-07-29 17:41:41,536 -</td>\n",
              "      <td>[main:QuorumPeerConfig@101] - Reading config...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-07-29 17:41:41,544 -</td>\n",
              "      <td>[main:QuorumPeerConfig@334] - Defaulting to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015-07-29 17:41:41,555 -</td>\n",
              "      <td>[main:DatadirCleanupManager@78] - autopurge....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015-07-29 17:41:41,555 -</td>\n",
              "      <td>[main:DatadirCleanupManager@79] - autopurge....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015-07-29 17:41:41,557 -</td>\n",
              "      <td>[main:DatadirCleanupManager@101] - Purge tas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74375</th>\n",
              "      <td>2015-08-25 11:26:27,898 -</td>\n",
              "      <td>[WorkerReceiver[myid=3]:FastLeaderElection@5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74376</th>\n",
              "      <td>2015-08-25 11:26:28,138 -</td>\n",
              "      <td>[LearnerHandler-/10.10.34.12:38330:LearnerHa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74377</th>\n",
              "      <td>2015-08-25 11:26:28,159 -</td>\n",
              "      <td>[LearnerHandler-/10.10.34.12:38330:LearnerHa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74378</th>\n",
              "      <td>2015-08-25 11:26:28,159 -</td>\n",
              "      <td>[LearnerHandler-/10.10.34.12:38330:LearnerHa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74379</th>\n",
              "      <td>2015-08-25 11:26:28,159 -</td>\n",
              "      <td>[LearnerHandler-/10.10.34.12:38330:LearnerHa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>74380 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Date&Time                                            Message\n",
              "0      2015-07-29 17:41:41,536 -     [main:QuorumPeerConfig@101] - Reading config...\n",
              "1      2015-07-29 17:41:41,544 -     [main:QuorumPeerConfig@334] - Defaulting to ...\n",
              "2      2015-07-29 17:41:41,555 -     [main:DatadirCleanupManager@78] - autopurge....\n",
              "3      2015-07-29 17:41:41,555 -     [main:DatadirCleanupManager@79] - autopurge....\n",
              "4      2015-07-29 17:41:41,557 -     [main:DatadirCleanupManager@101] - Purge tas...\n",
              "...                           ...                                                ...\n",
              "74375  2015-08-25 11:26:27,898 -     [WorkerReceiver[myid=3]:FastLeaderElection@5...\n",
              "74376  2015-08-25 11:26:28,138 -     [LearnerHandler-/10.10.34.12:38330:LearnerHa...\n",
              "74377  2015-08-25 11:26:28,159 -     [LearnerHandler-/10.10.34.12:38330:LearnerHa...\n",
              "74378  2015-08-25 11:26:28,159 -     [LearnerHandler-/10.10.34.12:38330:LearnerHa...\n",
              "74379  2015-08-25 11:26:28,159 -     [LearnerHandler-/10.10.34.12:38330:LearnerHa...\n",
              "\n",
              "[74380 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEe6U53aG5AO"
      },
      "source": [
        "df=df.sample(25000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTzw_gAV_FHt"
      },
      "source": [
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import PorterStemmer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvU9H6NC7bgF",
        "outputId": "2169c141-1856-4e35-baa8-16366a3de795"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVI86T7r_Njz"
      },
      "source": [
        "STOPWORDS=stopwords.words(\"english\") #stopwords are the most common unnecessary words. eg is, he, that, etc."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uT1iuf4_SRH"
      },
      "source": [
        "def deEmojify(text):\n",
        "    regrex_pattern = re.compile(pattern = \"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           \"]+\", flags = re.UNICODE)\n",
        "    return regrex_pattern.sub(r'',text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY6NnnhJ_VA1"
      },
      "source": [
        "import string   \n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    ps=PorterStemmer()\n",
        "    \n",
        "    text=deEmojify(text) # remove emojis\n",
        "    text_cleaned=\"\".join([x for x in text if x not in string.punctuation]) # remove punctuation\n",
        "\n",
        "    text_cleaned=re.sub(' +', ' ', text_cleaned) # remove extra white spaces\n",
        "    text_cleaned=text_cleaned.lower() # converting to lowercase\n",
        "    tokens=text_cleaned.split(\" \")\n",
        "    tokens=[token for token in tokens if token not in STOPWORDS] # Taking only those words which are not stopwords\n",
        "    stemmed=[ps.stem(token) for token in tokens]\n",
        "    text_cleaned=\" \".join([ps.stem(token) for token in tokens])\n",
        "    return text_cleaned"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RR7kVHm_mQ7y"
      },
      "source": [
        "df['Message']=df['Message'].apply(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySdFEBL6mRZL"
      },
      "source": [
        "df['cleaned_comments']=df['Message'].apply(lambda x:clean_text(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbhVELnFmTS-",
        "outputId": "af7087de-c32b-487b-bf3e-b98f648a0aa5"
      },
      "source": [
        "from collections import Counter\n",
        "dt=df['Message']\n",
        "p = Counter(\" \".join(dt).split()).most_common(50)\n",
        "rslt = pd.DataFrame(p, columns=['Word', 'Frequency'])\n",
        "print(rslt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 Word  Frequency\n",
            "0                                                None      16472\n",
            "1                                                   -       8556\n",
            "2                                          connection       4873\n",
            "3                                             request       3574\n",
            "4                                            Received       3569\n",
            "5                                             session       2506\n",
            "6                                                 for       1948\n",
            "7                                              socket       1304\n",
            "8                                              client       1267\n",
            "9                                             timeout       1212\n",
            "10  [/10.10.34.11:3888:QuorumCnxManager$Listener@493]       1212\n",
            "11  [/10.10.34.12:3888:QuorumCnxManager$Listener@493]       1204\n",
            "12  [/10.10.34.13:3888:QuorumCnxManager$Listener@493]       1153\n",
            "13                                                 to        731\n",
            "14                                               from        663\n",
            "15                                             Closed        655\n",
            "16  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIO...        649\n",
            "17                                           Accepted        649\n",
            "18                                               with        642\n",
            "19  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIO...        636\n",
            "20                                             Client        620\n",
            "21                                         attempting        620\n",
            "22                                                 at        620\n",
            "23                                                 of        616\n",
            "24               cport:-1)::PrepRequestProcessor@476]        616\n",
            "25                                          Processed        616\n",
            "26                                        termination        616\n",
            "27                                         sessionid:        616\n",
            "28                                        Established        612\n",
            "29                                         negotiated        612\n",
            "30                                                new        605\n",
            "31               [SessionTracker:ZooKeeperServer@325]        600\n",
            "32                                           Expiring        600\n",
            "33                                           exceeded        600\n",
            "34                                              which        597\n",
            "35                                                had        597\n",
            "36                                          sessionid        597\n",
            "37  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:Zoo...        594\n",
            "38                                          establish        594\n",
            "39                                              10000        560\n",
            "40                                            10000ms        537\n",
            "41                               [ProcessThread(sid:2        464\n",
            "42                                       Notification        449\n",
            "43                                               time        449\n",
            "44                                               out:        449\n",
            "45  [QuorumPeer[myid=1]/0:0:0:0:0:0:0:0:2181:FastL...        420\n",
            "46                                              60000        408\n",
            "47                                            LOOKING        247\n",
            "48            [CommitProcessor:3:ZooKeeperServer@595]        202\n",
            "49            [CommitProcessor:2:ZooKeeperServer@595]        198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXUhMnwOmXQY"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5pXubNYma8J",
        "outputId": "d204ef63-16d4-4f4c-d52f-9c2bcb721239"
      },
      "source": [
        "!pip install wordcloud"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (1.5.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from wordcloud) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMMserhgmfd4"
      },
      "source": [
        "X=df[['cleaned_comments']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "UIUyd2bhmiFJ",
        "outputId": "895ae446-53de-4da5-b666-f015f2e1473b"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18603</th>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14764</th>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28581</th>\n",
              "      <td>101034123888quorumcnxmanagerlistener493 recei...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6667</th>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27363</th>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59003</th>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15824</th>\n",
              "      <td>101034113888quorumcnxmanagerlistener493 recei...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24663</th>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67557</th>\n",
              "      <td>101034133888quorumcnxmanagerlistener493 recei...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57854</th>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        cleaned_comments\n",
              "18603                                               none\n",
              "14764                                               none\n",
              "28581   101034123888quorumcnxmanagerlistener493 recei...\n",
              "6667                                                none\n",
              "27363                                               none\n",
              "...                                                  ...\n",
              "59003                                               none\n",
              "15824   101034113888quorumcnxmanagerlistener493 recei...\n",
              "24663                                               none\n",
              "67557   101034133888quorumcnxmanagerlistener493 recei...\n",
              "57854                                               none\n",
              "\n",
              "[25000 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXmYBwNWmliB"
      },
      "source": [
        "X_data=X.iloc[:,:].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBw8ClnTmoH3",
        "outputId": "187467ce-8785-4887-de41-38fe59d0ca56"
      },
      "source": [
        "X_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['none'],\n",
              "       ['none'],\n",
              "       [' 101034123888quorumcnxmanagerlistener493 receiv connect request 1010341254945'],\n",
              "       ...,\n",
              "       ['none'],\n",
              "       [' 101034133888quorumcnxmanagerlistener493 receiv connect request 1010341249861'],\n",
              "       ['none']], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFvxPXDPmqS9"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=50,ngram_range=(2,2))\n",
        "X_data_vectored = vectorizer.fit_transform(X_data.ravel())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E7sT_KnmsQT",
        "outputId": "db4c1c2d-b5fa-4e3a-ba37-33cd71d0a63a"
      },
      "source": [
        "X_data_vectored"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<25000x50 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 29008 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YgZ8g_kmvMV",
        "outputId": "af59ab5a-ed9c-4395-8ceb-60d2257fffb3"
      },
      "source": [
        "!pip install sparse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sparse in /usr/local/lib/python3.7/dist-packages (0.13.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from sparse) (1.19.5)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from sparse) (0.51.2)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.7/dist-packages (from sparse) (1.4.1)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->sparse) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->sparse) (57.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZOzBCXWmxq2"
      },
      "source": [
        "X_data_array=X_data_vectored.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUCytOU-mzYj",
        "outputId": "38ffdf99-32ea-443d-ff6f-03750bb7cc62"
      },
      "source": [
        "X_data_array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJfCylXim1SC",
        "outputId": "032cffd9-09ec-4961-a997-ad4cbb458241"
      },
      "source": [
        "X_data_array.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "diblNUsCm3OX",
        "outputId": "98b00f5e-95b0-4746-d875-84c39b5a19a1"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "wcss = []\n",
        "for i in range(1, 10):\n",
        "    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n",
        "    kmeans.fit(X_data_array)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "plt.plot(range(1, 10), wcss)\n",
        "plt.title('The Elbow Method')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('WCSS')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHm3S669nsh2"
      },
      "source": [
        "***Method 1 ~ K Measn Clustering***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCI2_dpwm5WC"
      },
      "source": [
        "kmeans = KMeans(n_clusters = 5, init = 'k-means++', random_state = 42)\n",
        "y_kmeans = kmeans.fit_predict(X_data_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5UiOVLrn4ZK"
      },
      "source": [
        "**Labels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKdprQgXm9ST",
        "outputId": "001ee55f-ab7c-454f-ccd6-12694673f0cb"
      },
      "source": [
        "print(y_kmeans)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 2 ... 0 4 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lxm19KZ_n9UE"
      },
      "source": [
        "***Method 2 ~ Fuzzy Clustering***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-svOV1IL0hzS",
        "outputId": "81051510-ffc9-46ac-81a1-16dc6314399f"
      },
      "source": [
        "!pip install sklearn_extensions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sklearn_extensions in /usr/local/lib/python3.7/dist-packages (0.0.2)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from sklearn_extensions) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from sklearn_extensions) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.15 in /usr/local/lib/python3.7/dist-packages (from sklearn_extensions) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.15->sklearn_extensions) (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iazxg9vwEawW",
        "outputId": "86a028fa-f68a-4518-eac1-c9d65f2aa300"
      },
      "source": [
        "from sklearn_extensions.fuzzy_kmeans import FuzzyKMeans\n",
        "fuzzy_kmeans = FuzzyKMeans(k=3, m=2)\n",
        "fuzzy_kmeans.fit(X_data_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FuzzyKMeans(k=3, m=2, max_iter=100, random_state=0, tol=0.0001)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En57n75FweD_",
        "outputId": "6c7bf037-c6ee-432b-8c0a-d6d4749c8ac4"
      },
      "source": [
        "fuzzy_kmeans.labels_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 0, ..., 2, 0, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUH4BhUtoB3d"
      },
      "source": [
        "***Method 3 ~ Gaussian Mixture Models***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YCG8T1uA01A"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.mixture import GaussianMixture"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb44EsOlBmHK"
      },
      "source": [
        "gm = GaussianMixture(n_components=5, random_state=0).fit(X_data_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TjdJyBNi4ZJ"
      },
      "source": [
        "y_gmm=gm.predict(X_data_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzxyIcf1i4fp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e7a30b1-52c7-4e4c-eeee-3fb8907ef9a7"
      },
      "source": [
        "y_gmm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 2, ..., 0, 3, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiX7vnNFoT2g"
      },
      "source": [
        "***Method 5 ~ Agglomerative Clustering***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro4MgJM1EKVu"
      },
      "source": [
        "from sklearn.cluster import AgglomerativeClustering"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKSD9XWTENgi"
      },
      "source": [
        "clustering = AgglomerativeClustering().fit(X_data_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TP-EgJNEVHQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27c3c5b3-5275-49d8-8775-aff267df74fe"
      },
      "source": [
        "clustering.labels_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eCQbHXCon4Z"
      },
      "source": [
        "***Method 6 ~ AC - Complete***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gCGFkU7EYLK"
      },
      "source": [
        "#AC-complete"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vR9WA3bEx3a"
      },
      "source": [
        "clustering_C = AgglomerativeClustering(linkage='complete').fit(X_data_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m9M-osZE1Mx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c50f016-4963-47ad-dea1-51771b855d79"
      },
      "source": [
        "clustering_C.labels_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAQCCMXmotV3"
      },
      "source": [
        "***Method 7 ~ Robust Continuous Clustering***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Zd8TOhDya2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "859b63dd-cd1d-48d9-979c-9e38c83b5ed6"
      },
      "source": [
        "import prrcc\n",
        "import numpy as np\n",
        "from sklearn.metrics import adjusted_mutual_info_score\n",
        "\n",
        "clusterer = prrcc.RccCluster(k=5,measure='cosine')\n",
        "\n",
        "P = clusterer.fit(X_data_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mu = 1.1085242694209114, lambda = 882.0616959031687, epsilon = 0.4157836139202118, delta = 0.4157836139202118\n",
            " Iter | Data \t | Smooth \t | Obj \t\n",
            " 1 | 0.0 | 8.772315055821046 | 8.772315055821046\n",
            " 2 | 0.46133173093427804 | 0.08150863429591795 | 0.542840365230196\n",
            " 3 | 0.4940960914525295 | 0.03779479962020412 | 0.5318908910727336\n",
            " 4 | 0.4942828018851092 | 0.03759770438719782 | 0.531880506272307\n",
            " 5 | 0.49420581965124705 | 0.037631862186324035 | 0.5318376818375711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB4xh-baIFJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60c1bcb0-0624-4ed5-c8e7-3d3d7837bc66"
      },
      "source": [
        "P"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0,     0,     1, ..., 24843, 24844, 24845], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpEzzKecozXo"
      },
      "source": [
        "***Method 8 ~ BIRCH Clustering***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfBerXWFIFfp"
      },
      "source": [
        "#BIRCH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53gC5jQrIg8s"
      },
      "source": [
        "from sklearn.cluster import Birch\n",
        "brc = Birch(n_clusters=5)\n",
        "brc.fit(X_data_array)\n",
        "y_pred=brc.predict(X_data_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njGC7o_1I39n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59315916-b47f-420e-b22d-518f34c8d9ab"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 4, 1, ..., 4, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-Hgk-Xjo5Lq"
      },
      "source": [
        "***Method 9 ~ DBSCAN Clustering***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7x5XPsdI4T3"
      },
      "source": [
        "#DBSCAN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf7aarHwJtcE"
      },
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "db = DBSCAN(eps=0.3, min_samples=10).fit(X_data_array)\n",
        "labels = db.labels_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0tN_p5PJ0ll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9803ca7e-d797-4e49-db4e-b399f0ecac1c"
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 0, 3, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uC2kjfRJ9q2"
      },
      "source": [
        "n_noise_ = list(labels).count(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRNxGVILKHsP"
      },
      "source": [
        "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIcOC4ZtKJQ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fa0489a-0be8-4923-9402-daa0c57dfd68"
      },
      "source": [
        "n_clusters_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_psKZQop5MM"
      },
      "source": [
        "**Method 10 ~ RCC with DR ( PCA)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1JcHIqhp9_M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bd66479-11a7-4527-b880-5efdb30db885"
      },
      "source": [
        "X_data_array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3Gx6GSxqoA6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "800a0120-824a-479a-b197-429a9e96800f"
      },
      "source": [
        "X_data_array.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLF4m2K0qUCQ"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=10)\n",
        "X_data_array_DR=pca.fit_transform(X_data_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciCmtLsvqu8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6044711a-6fe9-464d-8350-3fa12ced76ef"
      },
      "source": [
        "X_data_array_DR.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QoOL2Kwqvfm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef4ddda8-fc05-4cf7-cc32-5178344b131d"
      },
      "source": [
        "import prrcc\n",
        "import numpy as np\n",
        "from sklearn.metrics import adjusted_mutual_info_score\n",
        "\n",
        "clusterer = prrcc.RccCluster(measure='cosine')\n",
        "\n",
        "P = clusterer.fit(X_data_array_DR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mu = 0.0005813225984527505, lambda = 4.8063146283875255, epsilon = 0.013920282945036888, delta = 0.013920282945036888\n",
            " Iter | Data \t | Smooth \t | Obj \t\n",
            " 1 | 0.0 | 2.302228558898013e-05 | 2.302228558898013e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyfLkvilIzTc",
        "outputId": "b4b6285c-85bf-44bb-a702-a75d1302ce19"
      },
      "source": [
        "P"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0,     1,     2, ..., 21742,     7, 21743], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2tUBqMi-nlz"
      },
      "source": [
        "**Streamming Data Clustering with Robust Continuous Clustering with DR**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CmgwC3u-59s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d733929f-924c-40ad-9269-60cd577b93dc"
      },
      "source": [
        "import pandas as pd\n",
        "df_test = pd.read_csv('server.log', sep=\"INFO\",header=None,error_bad_lines=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhA0iEW4_3JQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "aeae05a5-ee5c-4ebc-93ab-3087da65472c"
      },
      "source": [
        "df_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[2021-10-18 14:10:23,726]</td>\n",
              "      <td>Reading configuration from: E:\\LogAnalysis\\ka...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[2021-10-18 14:10:23,748]</td>\n",
              "      <td>autopurge.snapRetainCount set to 3 (org.apach...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[2021-10-18 14:10:23,748]</td>\n",
              "      <td>autopurge.purgeInterval set to 0 (org.apache....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[2021-10-18 14:10:23,749]</td>\n",
              "      <td>Purge task is not scheduled. (org.apache.zook...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[2021-10-18 14:10:23,749] WARN Either no confi...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>289</th>\n",
              "      <td>[2021-10-18 14:55:52,370]</td>\n",
              "      <td>tickTime set to 3000 (org.apache.zookeeper.se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290</th>\n",
              "      <td>[2021-10-18 14:55:52,370]</td>\n",
              "      <td>minSessionTimeout set to -1 (org.apache.zooke...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291</th>\n",
              "      <td>[2021-10-18 14:55:52,370]</td>\n",
              "      <td>maxSessionTimeout set to -1 (org.apache.zooke...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292</th>\n",
              "      <td>[2021-10-18 14:55:52,491]</td>\n",
              "      <td>Using org.apache.zookeeper.server.NIOServerCn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293</th>\n",
              "      <td>[2021-10-18 14:55:52,500]</td>\n",
              "      <td>binding to port 0.0.0.0/0.0.0.0:2181 (org.apa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>294 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     0                                                  1\n",
              "0                           [2021-10-18 14:10:23,726]    Reading configuration from: E:\\LogAnalysis\\ka...\n",
              "1                           [2021-10-18 14:10:23,748]    autopurge.snapRetainCount set to 3 (org.apach...\n",
              "2                           [2021-10-18 14:10:23,748]    autopurge.purgeInterval set to 0 (org.apache....\n",
              "3                           [2021-10-18 14:10:23,749]    Purge task is not scheduled. (org.apache.zook...\n",
              "4    [2021-10-18 14:10:23,749] WARN Either no confi...                                               None\n",
              "..                                                 ...                                                ...\n",
              "289                         [2021-10-18 14:55:52,370]    tickTime set to 3000 (org.apache.zookeeper.se...\n",
              "290                         [2021-10-18 14:55:52,370]    minSessionTimeout set to -1 (org.apache.zooke...\n",
              "291                         [2021-10-18 14:55:52,370]    maxSessionTimeout set to -1 (org.apache.zooke...\n",
              "292                         [2021-10-18 14:55:52,491]    Using org.apache.zookeeper.server.NIOServerCn...\n",
              "293                         [2021-10-18 14:55:52,500]    binding to port 0.0.0.0/0.0.0.0:2181 (org.apa...\n",
              "\n",
              "[294 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDQU0-JA_6cK"
      },
      "source": [
        "df_test.columns=['Date&Time','Message']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXYCUC0CAnqf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "00350a15-f5f6-4c66-e00e-79cfd657cba0"
      },
      "source": [
        "df_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date&amp;Time</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[2021-10-18 14:10:23,726]</td>\n",
              "      <td>Reading configuration from: E:\\LogAnalysis\\ka...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[2021-10-18 14:10:23,748]</td>\n",
              "      <td>autopurge.snapRetainCount set to 3 (org.apach...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[2021-10-18 14:10:23,748]</td>\n",
              "      <td>autopurge.purgeInterval set to 0 (org.apache....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[2021-10-18 14:10:23,749]</td>\n",
              "      <td>Purge task is not scheduled. (org.apache.zook...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[2021-10-18 14:10:23,749] WARN Either no confi...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>289</th>\n",
              "      <td>[2021-10-18 14:55:52,370]</td>\n",
              "      <td>tickTime set to 3000 (org.apache.zookeeper.se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290</th>\n",
              "      <td>[2021-10-18 14:55:52,370]</td>\n",
              "      <td>minSessionTimeout set to -1 (org.apache.zooke...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291</th>\n",
              "      <td>[2021-10-18 14:55:52,370]</td>\n",
              "      <td>maxSessionTimeout set to -1 (org.apache.zooke...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292</th>\n",
              "      <td>[2021-10-18 14:55:52,491]</td>\n",
              "      <td>Using org.apache.zookeeper.server.NIOServerCn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293</th>\n",
              "      <td>[2021-10-18 14:55:52,500]</td>\n",
              "      <td>binding to port 0.0.0.0/0.0.0.0:2181 (org.apa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>294 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Date&Time                                            Message\n",
              "0                           [2021-10-18 14:10:23,726]    Reading configuration from: E:\\LogAnalysis\\ka...\n",
              "1                           [2021-10-18 14:10:23,748]    autopurge.snapRetainCount set to 3 (org.apach...\n",
              "2                           [2021-10-18 14:10:23,748]    autopurge.purgeInterval set to 0 (org.apache....\n",
              "3                           [2021-10-18 14:10:23,749]    Purge task is not scheduled. (org.apache.zook...\n",
              "4    [2021-10-18 14:10:23,749] WARN Either no confi...                                               None\n",
              "..                                                 ...                                                ...\n",
              "289                         [2021-10-18 14:55:52,370]    tickTime set to 3000 (org.apache.zookeeper.se...\n",
              "290                         [2021-10-18 14:55:52,370]    minSessionTimeout set to -1 (org.apache.zooke...\n",
              "291                         [2021-10-18 14:55:52,370]    maxSessionTimeout set to -1 (org.apache.zooke...\n",
              "292                         [2021-10-18 14:55:52,491]    Using org.apache.zookeeper.server.NIOServerCn...\n",
              "293                         [2021-10-18 14:55:52,500]    binding to port 0.0.0.0/0.0.0.0:2181 (org.apa...\n",
              "\n",
              "[294 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KIzJPMSAn0P"
      },
      "source": [
        "df_test['Message']=df_test['Message'].apply(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfQBL05yAsa1"
      },
      "source": [
        "df_test['cleaned_comments']=df_test['Message'].apply(lambda x:clean_text(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LcgcdQsAu3L"
      },
      "source": [
        "X_test_data=df[['cleaned_comments']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2stKfzkWAw11"
      },
      "source": [
        "X_data=X_test_data.iloc[:,:].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJQhNNtUAyjX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ac415d0-5d50-4209-b5f3-4de6e5ef91b7"
      },
      "source": [
        "X_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['none'],\n",
              "       ['none'],\n",
              "       [' 101034123888quorumcnxmanagerlistener493 receiv connect request 1010341254945'],\n",
              "       ...,\n",
              "       ['none'],\n",
              "       [' 101034133888quorumcnxmanagerlistener493 receiv connect request 1010341249861'],\n",
              "       ['none']], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtN9BbUJBBUk"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=100,ngram_range=(1,1))\n",
        "X_data_vectored = vectorizer.fit_transform(X_data.ravel())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-5Fz4kMJThW"
      },
      "source": [
        "X_data_array_test=X_data_vectored.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_4soaXcJrcB",
        "outputId": "3e9cb9a5-6965-4fd1-f8ef-007e8496e6c4"
      },
      "source": [
        "X_data_array_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8B1DP7MCMP0G",
        "outputId": "6261a265-3ebf-4281-f2fd-56f062d8389a"
      },
      "source": [
        "X_data_array_test[[1]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmNgoAXPK6Fh",
        "outputId": "9ce10652-5202-4d6c-8ac6-b5f3c5e3ed5c"
      },
      "source": [
        "X_data_array_test[1][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nkkKiafJssZ"
      },
      "source": [
        "log_list=df_test['Message']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0yPFxdOJ79a",
        "outputId": "556877ac-c5ea-428b-be6c-d4d106a8fd0d"
      },
      "source": [
        "for i in range(len(log_list)):\n",
        "  print('Processsing Log ',log_list[i])\n",
        "  y=kmeans.fit_predict(X_data_array_test[].reshape(-1,1))\n",
        "  print('The currrent log streammed and clustered into group of ',y)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processsing Log   Reading configuration from: E:\\LogAnalysis\\kafka\\config\\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log   Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Reading configuration from: E:\\LogAnalysis\\kafka\\config\\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Server environment:host.name=DESKTOP-767O0L9 (org.apache.zookeeper.server.ZooKeeperServer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log   Server environment:java.version=17 (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Server environment:java.home=C:\\Program Files\\Java\\jdk-17 (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 3 0 1 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0]\n",
            "Processsing Log   Server environment:java.class.path=E:\\LogAnalysis\\kafka\\libs\\activation-1.1.1.jar;E:\\LogAnalysis\\kafka\\libs\\aopalliance-repackaged-2.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\argparse4j-0.7.0.jar;E:\\LogAnalysis\\kafka\\libs\\audience-annotations-0.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\commons-lang3-3.8.1.jar;E:\\LogAnalysis\\kafka\\libs\\connect-api-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\connect-basic-auth-extension-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\connect-file-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\connect-json-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\connect-runtime-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\connect-transforms-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\guava-20.0.jar;E:\\LogAnalysis\\kafka\\libs\\hk2-api-2.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\hk2-locator-2.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\hk2-utils-2.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-annotations-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-core-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-databind-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-dataformat-csv-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-datatype-jdk8-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-jaxrs-base-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-jaxrs-json-provider-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-module-jaxb-annotations-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-module-paranamer-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-module-scala_2.11-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jakarta.annotation-api-1.3.4.jar;E:\\LogAnalysis\\kafka\\libs\\jakarta.inject-2.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\jakarta.ws.rs-api-2.1.5.jar;E:\\LogAnalysis\\kafka\\libs\\javassist-3.22.0-CR2.jar;E:\\LogAnalysis\\kafka\\libs\\javax.servlet-api-3.1.0.jar;E:\\LogAnalysis\\kafka\\libs\\javax.ws.rs-api-2.1.1.jar;E:\\LogAnalysis\\kafka\\libs\\jaxb-api-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-client-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-common-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-container-servlet-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-container-servlet-core-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-hk2-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-media-jaxb-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-server-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-client-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-continuation-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-http-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-io-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-security-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-server-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-servlet-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-servlets-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-util-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jopt-simple-5.0.4.jar;E:\\LogAnalysis\\kafka\\libs\\jsr305-3.0.2.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-clients-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-log4j-appender-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-streams-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-streams-examples-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-streams-scala_2.11-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-streams-test-utils-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-tools-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-javadoc.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-javadoc.jar.asc;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-scaladoc.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-scaladoc.jar.asc;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-sources.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-sources.jar.asc;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-test-sources.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-test-sources.jar.asc;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-test.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-test.jar.asc;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0.jar.asc;E:\\LogAnalysis\\kafka\\libs\\log4j-1.2.17.jar;E:\\LogAnalysis\\kafka\\libs\\lz4-java-1.6.0.jar;E:\\LogAnalysis\\kafka\\libs\\maven-artifact-3.6.1.jar;E:\\LogAnalysis\\kafka\\libs\\metrics-core-2.2.0.jar;E:\\LogAnalysis\\kafka\\libs\\osgi-resource-locator-1.0.1.jar;E:\\LogAnalysis\\kafka\\libs\\paranamer-2.8.jar;E:\\LogAnalysis\\kafka\\libs\\plexus-utils-3.2.0.jar;E:\\LogAnalysis\\kafka\\libs\\reflections-0.9.11.jar;E:\\LogAnalysis\\kafka\\libs\\rocksdbjni-5.18.3.jar;E:\\LogAnalysis\\kafka\\libs\\scala-library-2.11.12.jar;E:\\LogAnalysis\\kafka\\libs\\scala-logging_2.11-3.9.0.jar;E:\\LogAnalysis\\kafka\\libs\\scala-reflect-2.11.12.jar;E:\\LogAnalysis\\kafka\\libs\\slf4j-api-1.7.26.jar;E:\\LogAnalysis\\kafka\\libs\\slf4j-log4j12-1.7.26.jar;E:\\LogAnalysis\\kafka\\libs\\snappy-java-1.1.7.3.jar;E:\\LogAnalysis\\kafka\\libs\\spotbugs-annotations-3.1.9.jar;E:\\LogAnalysis\\kafka\\libs\\validation-api-2.0.1.Final.jar;E:\\LogAnalysis\\kafka\\libs\\zkclient-0.11.jar;E:\\LogAnalysis\\kafka\\libs\\zookeeper-3.4.14.jar;E:\\LogAnalysis\\kafka\\libs\\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Server environment:java.library.path=C:\\Program Files\\Java\\jdk-17\\bin;C:\\Windows\\Sun\\Java\\bin;C:\\Windows\\system32;C:\\Windows;C:\\Users\\Nagaraju\\anaconda3;C:\\Users\\Nagaraju\\anaconda3\\Library\\mingw-w64\\bin;C:\\Users\\Nagaraju\\anaconda3\\Library\\usr\\bin;C:\\Users\\Nagaraju\\anaconda3\\Library\\bin;C:\\Users\\Nagaraju\\anaconda3\\Scripts;C:\\Users\\Nagaraju\\anaconda3\\bin;C:\\Users\\Nagaraju\\anaconda3\\condabin;C:\\Users\\Nagaraju\\anaconda3;C:\\Users\\Nagaraju\\anaconda3\\Library\\mingw-w64\\bin;C:\\Users\\Nagaraju\\anaconda3\\Library\\usr\\bin;C:\\Users\\Nagaraju\\anaconda3\\Library\\bin;C:\\Users\\Nagaraju\\anaconda3\\Scripts;C:\\Program Files\\Common Files\\Oracle\\Java\\javapath;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0;C:\\Windows\\System32\\OpenSSH;C:\\Program Files\\Java\\jdk-14.0.2\\bin;C:\\Program Files\\Java\\jdk-14.0.2\\lib;E:\\LogAnalysis\\kafka\\bin\\windows;.;. (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Server environment:java.io.tmpdir=C:\\Users\\Nagaraju\\AppData\\Local\\Temp\\ (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Server environment:user.name=Nagaraju (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log   Server environment:user.home=C:\\Users\\Nagaraju (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Server environment:user.dir=C:\\Users\\Nagaraju (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 4 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 2 0 4 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0]\n",
            "Processsing Log   tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 4 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log   minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 3 0 0 0 0 0 0 0 0 2\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
            "Processsing Log   maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 3 0 0 0 0 0 0 2\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
            "Processsing Log   Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log   binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 4 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log   Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   starting (kafka.server.KafkaServer)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log   Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log   Client environment:host.name=DESKTOP-767O0L9 (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Client environment:java.version=17 (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 4 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log   Client environment:java.home=C:\\Program Files\\Java\\jdk-17 (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Client environment:java.class.path=E:\\LogAnalysis\\kafka\\libs\\activation-1.1.1.jar;E:\\LogAnalysis\\kafka\\libs\\aopalliance-repackaged-2.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\argparse4j-0.7.0.jar;E:\\LogAnalysis\\kafka\\libs\\audience-annotations-0.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\commons-lang3-3.8.1.jar;E:\\LogAnalysis\\kafka\\libs\\connect-api-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\connect-basic-auth-extension-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\connect-file-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\connect-json-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\connect-runtime-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\connect-transforms-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\guava-20.0.jar;E:\\LogAnalysis\\kafka\\libs\\hk2-api-2.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\hk2-locator-2.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\hk2-utils-2.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-annotations-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-core-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-databind-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-dataformat-csv-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-datatype-jdk8-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-jaxrs-base-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-jaxrs-json-provider-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-module-jaxb-annotations-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-module-paranamer-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-module-scala_2.11-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jakarta.annotation-api-1.3.4.jar;E:\\LogAnalysis\\kafka\\libs\\jakarta.inject-2.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\jakarta.ws.rs-api-2.1.5.jar;E:\\LogAnalysis\\kafka\\libs\\javassist-3.22.0-CR2.jar;E:\\LogAnalysis\\kafka\\libs\\javax.servlet-api-3.1.0.jar;E:\\LogAnalysis\\kafka\\libs\\javax.ws.rs-api-2.1.1.jar;E:\\LogAnalysis\\kafka\\libs\\jaxb-api-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-client-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-common-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-container-servlet-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-container-servlet-core-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-hk2-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-media-jaxb-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-server-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-client-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-continuation-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-http-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-io-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-security-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-server-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-servlet-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-servlets-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-util-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jopt-simple-5.0.4.jar;E:\\LogAnalysis\\kafka\\libs\\jsr305-3.0.2.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-clients-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-log4j-appender-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-streams-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-streams-examples-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-streams-scala_2.11-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-streams-test-utils-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-tools-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-javadoc.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-javadoc.jar.asc;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-scaladoc.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-scaladoc.jar.asc;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-sources.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-sources.jar.asc;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-test-sources.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-test-sources.jar.asc;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-test.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-test.jar.asc;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0.jar.asc;E:\\LogAnalysis\\kafka\\libs\\log4j-1.2.17.jar;E:\\LogAnalysis\\kafka\\libs\\lz4-java-1.6.0.jar;E:\\LogAnalysis\\kafka\\libs\\maven-artifact-3.6.1.jar;E:\\LogAnalysis\\kafka\\libs\\metrics-core-2.2.0.jar;E:\\LogAnalysis\\kafka\\libs\\osgi-resource-locator-1.0.1.jar;E:\\LogAnalysis\\kafka\\libs\\paranamer-2.8.jar;E:\\LogAnalysis\\kafka\\libs\\plexus-utils-3.2.0.jar;E:\\LogAnalysis\\kafka\\libs\\reflections-0.9.11.jar;E:\\LogAnalysis\\kafka\\libs\\rocksdbjni-5.18.3.jar;E:\\LogAnalysis\\kafka\\libs\\scala-library-2.11.12.jar;E:\\LogAnalysis\\kafka\\libs\\scala-logging_2.11-3.9.0.jar;E:\\LogAnalysis\\kafka\\libs\\scala-reflect-2.11.12.jar;E:\\LogAnalysis\\kafka\\libs\\slf4j-api-1.7.26.jar;E:\\LogAnalysis\\kafka\\libs\\slf4j-log4j12-1.7.26.jar;E:\\LogAnalysis\\kafka\\libs\\snappy-java-1.1.7.3.jar;E:\\LogAnalysis\\kafka\\libs\\spotbugs-annotations-3.1.9.jar;E:\\LogAnalysis\\kafka\\libs\\validation-api-2.0.1.Final.jar;E:\\LogAnalysis\\kafka\\libs\\zkclient-0.11.jar;E:\\LogAnalysis\\kafka\\libs\\zookeeper-3.4.14.jar;E:\\LogAnalysis\\kafka\\libs\\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log   Client environment:java.library.path=C:\\Program Files\\Java\\jdk-17\\bin;C:\\Windows\\Sun\\Java\\bin;C:\\Windows\\system32;C:\\Windows;C:\\Users\\Nagaraju\\anaconda3;C:\\Users\\Nagaraju\\anaconda3\\Library\\mingw-w64\\bin;C:\\Users\\Nagaraju\\anaconda3\\Library\\usr\\bin;C:\\Users\\Nagaraju\\anaconda3\\Library\\bin;C:\\Users\\Nagaraju\\anaconda3\\Scripts;C:\\Users\\Nagaraju\\anaconda3\\bin;C:\\Users\\Nagaraju\\anaconda3\\condabin;C:\\Users\\Nagaraju\\anaconda3;C:\\Users\\Nagaraju\\anaconda3\\Library\\mingw-w64\\bin;C:\\Users\\Nagaraju\\anaconda3\\Library\\usr\\bin;C:\\Users\\Nagaraju\\anaconda3\\Library\\bin;C:\\Users\\Nagaraju\\anaconda3\\Scripts;C:\\Program Files\\Common Files\\Oracle\\Java\\javapath;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0;C:\\Windows\\System32\\OpenSSH;C:\\Program Files\\Java\\jdk-14.0.2\\bin;C:\\Program Files\\Java\\jdk-14.0.2\\lib;E:\\LogAnalysis\\kafka\\bin\\windows;.;. (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Client environment:java.io.tmpdir=C:\\Users\\Nagaraju\\AppData\\Local\\Temp\\ (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0]\n",
            "Processsing Log   Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log   Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 3 0 1 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0]\n",
            "Processsing Log   Client environment:user.name=Nagaraju (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Client environment:user.home=C:\\Users\\Nagaraju (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 4 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 2 0 4 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0]\n",
            "Processsing Log   Client environment:user.dir=C:\\Users\\Nagaraju (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log   Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@46b61c56 (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 3 0 1 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 0 0 0 0 0 0 0 0 3\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 4 4 4 4 4 4 4 2 4 4 4 4 4 4\n",
            " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
            " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 4 4 4 4 4 4 4 4 4 4 4]\n",
            "Processsing Log   [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Session: 0x0 closed (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   EventThread shut down for session: 0x0 (org.apache.zookeeper.ClientCnxn)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 0 0 0 0 0 0 0 0 3\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log   [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 3 0 4 3 3 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 1 0]\n",
            "Processsing Log  None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 0 0 0 0 0 0 0 0 3\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 3 0 0 0 0 0 0 2\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 4 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   shutting down (kafka.server.KafkaServer)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   shut down completed (kafka.server.KafkaServer)\n",
            "The currrent log streammed and clustered into group of  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   shutting down (kafka.server.KafkaServer)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log   Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   starting (kafka.server.KafkaServer)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Client environment:host.name=DESKTOP-767O0L9 (org.apache.zookeeper.ZooKeeper)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Client environment:java.version=17 (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 4 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 2 0 4 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0]\n",
            "Processsing Log   Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Client environment:java.home=C:\\Program Files\\Java\\jdk-17 (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log   Client environment:java.class.path=E:\\LogAnalysis\\kafka\\libs\\activation-1.1.1.jar;E:\\LogAnalysis\\kafka\\libs\\aopalliance-repackaged-2.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\argparse4j-0.7.0.jar;E:\\LogAnalysis\\kafka\\libs\\audience-annotations-0.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\commons-lang3-3.8.1.jar;E:\\LogAnalysis\\kafka\\libs\\connect-api-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\connect-basic-auth-extension-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\connect-file-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\connect-json-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\connect-runtime-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\connect-transforms-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\guava-20.0.jar;E:\\LogAnalysis\\kafka\\libs\\hk2-api-2.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\hk2-locator-2.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\hk2-utils-2.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-annotations-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-core-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-databind-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-dataformat-csv-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-datatype-jdk8-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-jaxrs-base-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-jaxrs-json-provider-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-module-jaxb-annotations-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-module-paranamer-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-module-scala_2.11-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jakarta.annotation-api-1.3.4.jar;E:\\LogAnalysis\\kafka\\libs\\jakarta.inject-2.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\jakarta.ws.rs-api-2.1.5.jar;E:\\LogAnalysis\\kafka\\libs\\javassist-3.22.0-CR2.jar;E:\\LogAnalysis\\kafka\\libs\\javax.servlet-api-3.1.0.jar;E:\\LogAnalysis\\kafka\\libs\\javax.ws.rs-api-2.1.1.jar;E:\\LogAnalysis\\kafka\\libs\\jaxb-api-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-client-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-common-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-container-servlet-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-container-servlet-core-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-hk2-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-media-jaxb-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-server-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-client-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-continuation-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-http-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-io-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-security-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-server-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-servlet-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-servlets-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-util-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jopt-simple-5.0.4.jar;E:\\LogAnalysis\\kafka\\libs\\jsr305-3.0.2.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-clients-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-log4j-appender-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-streams-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-streams-examples-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-streams-scala_2.11-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-streams-test-utils-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-tools-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-javadoc.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-javadoc.jar.asc;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-scaladoc.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-scaladoc.jar.asc;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-sources.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-sources.jar.asc;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-test-sources.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-test-sources.jar.asc;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-test.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-test.jar.asc;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0.jar.asc;E:\\LogAnalysis\\kafka\\libs\\log4j-1.2.17.jar;E:\\LogAnalysis\\kafka\\libs\\lz4-java-1.6.0.jar;E:\\LogAnalysis\\kafka\\libs\\maven-artifact-3.6.1.jar;E:\\LogAnalysis\\kafka\\libs\\metrics-core-2.2.0.jar;E:\\LogAnalysis\\kafka\\libs\\osgi-resource-locator-1.0.1.jar;E:\\LogAnalysis\\kafka\\libs\\paranamer-2.8.jar;E:\\LogAnalysis\\kafka\\libs\\plexus-utils-3.2.0.jar;E:\\LogAnalysis\\kafka\\libs\\reflections-0.9.11.jar;E:\\LogAnalysis\\kafka\\libs\\rocksdbjni-5.18.3.jar;E:\\LogAnalysis\\kafka\\libs\\scala-library-2.11.12.jar;E:\\LogAnalysis\\kafka\\libs\\scala-logging_2.11-3.9.0.jar;E:\\LogAnalysis\\kafka\\libs\\scala-reflect-2.11.12.jar;E:\\LogAnalysis\\kafka\\libs\\slf4j-api-1.7.26.jar;E:\\LogAnalysis\\kafka\\libs\\slf4j-log4j12-1.7.26.jar;E:\\LogAnalysis\\kafka\\libs\\snappy-java-1.1.7.3.jar;E:\\LogAnalysis\\kafka\\libs\\spotbugs-annotations-3.1.9.jar;E:\\LogAnalysis\\kafka\\libs\\validation-api-2.0.1.Final.jar;E:\\LogAnalysis\\kafka\\libs\\zkclient-0.11.jar;E:\\LogAnalysis\\kafka\\libs\\zookeeper-3.4.14.jar;E:\\LogAnalysis\\kafka\\libs\\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Client environment:java.library.path=C:\\Program Files\\Java\\jdk-17\\bin;C:\\Windows\\Sun\\Java\\bin;C:\\Windows\\system32;C:\\Windows;C:\\Users\\Nagaraju\\anaconda3;C:\\Users\\Nagaraju\\anaconda3\\Library\\mingw-w64\\bin;C:\\Users\\Nagaraju\\anaconda3\\Library\\usr\\bin;C:\\Users\\Nagaraju\\anaconda3\\Library\\bin;C:\\Users\\Nagaraju\\anaconda3\\Scripts;C:\\Users\\Nagaraju\\anaconda3\\bin;C:\\Users\\Nagaraju\\anaconda3\\condabin;C:\\Users\\Nagaraju\\anaconda3;C:\\Users\\Nagaraju\\anaconda3\\Library\\mingw-w64\\bin;C:\\Users\\Nagaraju\\anaconda3\\Library\\usr\\bin;C:\\Users\\Nagaraju\\anaconda3\\Library\\bin;C:\\Users\\Nagaraju\\anaconda3\\Scripts;C:\\Program Files\\Common Files\\Oracle\\Java\\javapath;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0;C:\\Windows\\System32\\OpenSSH;C:\\Program Files\\Java\\jdk-14.0.2\\bin;C:\\Program Files\\Java\\jdk-14.0.2\\lib;E:\\LogAnalysis\\kafka\\bin\\windows;.;. (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Client environment:java.io.tmpdir=C:\\Users\\Nagaraju\\AppData\\Local\\Temp\\ (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Client environment:user.name=Nagaraju (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Client environment:user.home=C:\\Users\\Nagaraju (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Client environment:user.dir=C:\\Users\\Nagaraju (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 0 0 0 0 0 0 0 0 3\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log   Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@481ba2cf (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 3 0 0 0 0 0 0 0 0 2\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 4 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 2 3 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 4 0 0 0 3 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 3 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Session: 0x0 closed (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   EventThread shut down for session: 0x0 (org.apache.zookeeper.ClientCnxn)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log   [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 4 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 0 0 0 0 0 0 0 0 3\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 0 0 0 0 0 0 0 0 3\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 4 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 2 0 4 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 3 0 0 0 0 0 0 0 2\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 4 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 2 0 4 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0]\n",
            "Processsing Log   shutting down (kafka.server.KafkaServer)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log   shut down completed (kafka.server.KafkaServer)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 4 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 2 0 4 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   shutting down (kafka.server.KafkaServer)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   starting (kafka.server.KafkaServer)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 4 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log   Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 4 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 2 0 4 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0]\n",
            "Processsing Log   Client environment:host.name=DESKTOP-767O0L9 (org.apache.zookeeper.ZooKeeper)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log   Client environment:java.version=17 (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 0 0 0 0 0 0 0 0 3\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log   Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 3 0 0 0 0 0 0 0 0 2\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
            "Processsing Log   Client environment:java.home=C:\\Program Files\\Java\\jdk-17 (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Client environment:java.class.path=E:\\LogAnalysis\\kafka\\libs\\activation-1.1.1.jar;E:\\LogAnalysis\\kafka\\libs\\aopalliance-repackaged-2.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\argparse4j-0.7.0.jar;E:\\LogAnalysis\\kafka\\libs\\audience-annotations-0.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\commons-lang3-3.8.1.jar;E:\\LogAnalysis\\kafka\\libs\\connect-api-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\connect-basic-auth-extension-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\connect-file-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\connect-json-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\connect-runtime-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\connect-transforms-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\guava-20.0.jar;E:\\LogAnalysis\\kafka\\libs\\hk2-api-2.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\hk2-locator-2.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\hk2-utils-2.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-annotations-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-core-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-databind-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-dataformat-csv-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-datatype-jdk8-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-jaxrs-base-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-jaxrs-json-provider-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-module-jaxb-annotations-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-module-paranamer-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-module-scala_2.11-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jakarta.annotation-api-1.3.4.jar;E:\\LogAnalysis\\kafka\\libs\\jakarta.inject-2.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\jakarta.ws.rs-api-2.1.5.jar;E:\\LogAnalysis\\kafka\\libs\\javassist-3.22.0-CR2.jar;E:\\LogAnalysis\\kafka\\libs\\javax.servlet-api-3.1.0.jar;E:\\LogAnalysis\\kafka\\libs\\javax.ws.rs-api-2.1.1.jar;E:\\LogAnalysis\\kafka\\libs\\jaxb-api-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-client-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-common-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-container-servlet-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-container-servlet-core-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-hk2-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-media-jaxb-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-server-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-client-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-continuation-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-http-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-io-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-security-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-server-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-servlet-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-servlets-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-util-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jopt-simple-5.0.4.jar;E:\\LogAnalysis\\kafka\\libs\\jsr305-3.0.2.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-clients-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-log4j-appender-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-streams-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-streams-examples-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-streams-scala_2.11-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-streams-test-utils-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-tools-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-javadoc.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-javadoc.jar.asc;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-scaladoc.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-scaladoc.jar.asc;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-sources.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-sources.jar.asc;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-test-sources.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-test-sources.jar.asc;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-test.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-test.jar.asc;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0.jar.asc;E:\\LogAnalysis\\kafka\\libs\\log4j-1.2.17.jar;E:\\LogAnalysis\\kafka\\libs\\lz4-java-1.6.0.jar;E:\\LogAnalysis\\kafka\\libs\\maven-artifact-3.6.1.jar;E:\\LogAnalysis\\kafka\\libs\\metrics-core-2.2.0.jar;E:\\LogAnalysis\\kafka\\libs\\osgi-resource-locator-1.0.1.jar;E:\\LogAnalysis\\kafka\\libs\\paranamer-2.8.jar;E:\\LogAnalysis\\kafka\\libs\\plexus-utils-3.2.0.jar;E:\\LogAnalysis\\kafka\\libs\\reflections-0.9.11.jar;E:\\LogAnalysis\\kafka\\libs\\rocksdbjni-5.18.3.jar;E:\\LogAnalysis\\kafka\\libs\\scala-library-2.11.12.jar;E:\\LogAnalysis\\kafka\\libs\\scala-logging_2.11-3.9.0.jar;E:\\LogAnalysis\\kafka\\libs\\scala-reflect-2.11.12.jar;E:\\LogAnalysis\\kafka\\libs\\slf4j-api-1.7.26.jar;E:\\LogAnalysis\\kafka\\libs\\slf4j-log4j12-1.7.26.jar;E:\\LogAnalysis\\kafka\\libs\\snappy-java-1.1.7.3.jar;E:\\LogAnalysis\\kafka\\libs\\spotbugs-annotations-3.1.9.jar;E:\\LogAnalysis\\kafka\\libs\\validation-api-2.0.1.Final.jar;E:\\LogAnalysis\\kafka\\libs\\zkclient-0.11.jar;E:\\LogAnalysis\\kafka\\libs\\zookeeper-3.4.14.jar;E:\\LogAnalysis\\kafka\\libs\\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Client environment:java.library.path=C:\\Program Files\\Java\\jdk-17\\bin;C:\\Windows\\Sun\\Java\\bin;C:\\Windows\\system32;C:\\Windows;C:\\Users\\Nagaraju\\anaconda3;C:\\Users\\Nagaraju\\anaconda3\\Library\\mingw-w64\\bin;C:\\Users\\Nagaraju\\anaconda3\\Library\\usr\\bin;C:\\Users\\Nagaraju\\anaconda3\\Library\\bin;C:\\Users\\Nagaraju\\anaconda3\\Scripts;C:\\Users\\Nagaraju\\anaconda3\\bin;C:\\Users\\Nagaraju\\anaconda3\\condabin;C:\\Users\\Nagaraju\\anaconda3;C:\\Users\\Nagaraju\\anaconda3\\Library\\mingw-w64\\bin;C:\\Users\\Nagaraju\\anaconda3\\Library\\usr\\bin;C:\\Users\\Nagaraju\\anaconda3\\Library\\bin;C:\\Users\\Nagaraju\\anaconda3\\Scripts;C:\\Program Files\\Common Files\\Oracle\\Java\\javapath;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0;C:\\Windows\\System32\\OpenSSH;C:\\Program Files\\Java\\jdk-14.0.2\\bin;C:\\Program Files\\Java\\jdk-14.0.2\\lib;E:\\LogAnalysis\\kafka\\bin\\windows;.;. (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Client environment:java.io.tmpdir=C:\\Users\\Nagaraju\\AppData\\Local\\Temp\\ (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0]\n",
            "Processsing Log   Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Client environment:user.name=Nagaraju (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 4 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 2 3 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            "Processsing Log   Client environment:user.home=C:\\Users\\Nagaraju (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Client environment:user.dir=C:\\Users\\Nagaraju (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@481ba2cf (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 4 4 4 4 4 4 4 2 4 4 4 4 4 4\n",
            " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
            " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 4 4 4 4 4 4 4 4 4 4 4]\n",
            "Processsing Log   [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 4 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 2 3 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 4 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 2 0 4 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Session: 0x0 closed (org.apache.zookeeper.ZooKeeper)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 4 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 2 3 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            "Processsing Log   EventThread shut down for session: 0x0 (org.apache.zookeeper.ClientCnxn)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 0 0 0 0 0 0 0 0 3\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log   [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 4 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 4 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 2 0 4 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0]\n",
            "Processsing Log  None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 4 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 2 0 4 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 2 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 3 4 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   shutting down (kafka.server.KafkaServer)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log   shut down completed (kafka.server.KafkaServer)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   shutting down (kafka.server.KafkaServer)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 0 0 0 0 0 0 0 0 3\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log   Reading configuration from: E:\\LogAnalysis\\kafka\\config\\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log   autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 3 0 0 0 0 0 0 0 0 2\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
            "Processsing Log  None\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 3 0 0 0 0 0 0 2\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
            "Processsing Log   Reading configuration from: E:\\LogAnalysis\\kafka\\config\\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 4 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log   Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Server environment:host.name=DESKTOP-767O0L9 (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Server environment:java.version=17 (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 4 1 0 0 0\n",
            " 0 0 0 0 0 0 0 0 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 3 0 0 0 0 0 0 1 0 0 0 0 0 0 4 0 0 2 0 0 0]\n",
            "Processsing Log   Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Server environment:java.home=C:\\Program Files\\Java\\jdk-17 (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Server environment:java.class.path=E:\\LogAnalysis\\kafka\\libs\\activation-1.1.1.jar;E:\\LogAnalysis\\kafka\\libs\\aopalliance-repackaged-2.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\argparse4j-0.7.0.jar;E:\\LogAnalysis\\kafka\\libs\\audience-annotations-0.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\commons-lang3-3.8.1.jar;E:\\LogAnalysis\\kafka\\libs\\connect-api-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\connect-basic-auth-extension-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\connect-file-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\connect-json-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\connect-runtime-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\connect-transforms-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\guava-20.0.jar;E:\\LogAnalysis\\kafka\\libs\\hk2-api-2.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\hk2-locator-2.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\hk2-utils-2.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-annotations-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-core-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-databind-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-dataformat-csv-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-datatype-jdk8-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-jaxrs-base-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-jaxrs-json-provider-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-module-jaxb-annotations-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-module-paranamer-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jackson-module-scala_2.11-2.9.9.jar;E:\\LogAnalysis\\kafka\\libs\\jakarta.annotation-api-1.3.4.jar;E:\\LogAnalysis\\kafka\\libs\\jakarta.inject-2.5.0.jar;E:\\LogAnalysis\\kafka\\libs\\jakarta.ws.rs-api-2.1.5.jar;E:\\LogAnalysis\\kafka\\libs\\javassist-3.22.0-CR2.jar;E:\\LogAnalysis\\kafka\\libs\\javax.servlet-api-3.1.0.jar;E:\\LogAnalysis\\kafka\\libs\\javax.ws.rs-api-2.1.1.jar;E:\\LogAnalysis\\kafka\\libs\\jaxb-api-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-client-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-common-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-container-servlet-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-container-servlet-core-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-hk2-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-media-jaxb-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jersey-server-2.28.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-client-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-continuation-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-http-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-io-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-security-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-server-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-servlet-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-servlets-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jetty-util-9.4.18.v20190429.jar;E:\\LogAnalysis\\kafka\\libs\\jopt-simple-5.0.4.jar;E:\\LogAnalysis\\kafka\\libs\\jsr305-3.0.2.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-clients-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-log4j-appender-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-streams-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-streams-examples-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-streams-scala_2.11-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-streams-test-utils-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka-tools-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-javadoc.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-javadoc.jar.asc;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-scaladoc.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-scaladoc.jar.asc;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-sources.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-sources.jar.asc;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-test-sources.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-test-sources.jar.asc;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-test.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0-test.jar.asc;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0.jar;E:\\LogAnalysis\\kafka\\libs\\kafka_2.11-2.3.0.jar.asc;E:\\LogAnalysis\\kafka\\libs\\log4j-1.2.17.jar;E:\\LogAnalysis\\kafka\\libs\\lz4-java-1.6.0.jar;E:\\LogAnalysis\\kafka\\libs\\maven-artifact-3.6.1.jar;E:\\LogAnalysis\\kafka\\libs\\metrics-core-2.2.0.jar;E:\\LogAnalysis\\kafka\\libs\\osgi-resource-locator-1.0.1.jar;E:\\LogAnalysis\\kafka\\libs\\paranamer-2.8.jar;E:\\LogAnalysis\\kafka\\libs\\plexus-utils-3.2.0.jar;E:\\LogAnalysis\\kafka\\libs\\reflections-0.9.11.jar;E:\\LogAnalysis\\kafka\\libs\\rocksdbjni-5.18.3.jar;E:\\LogAnalysis\\kafka\\libs\\scala-library-2.11.12.jar;E:\\LogAnalysis\\kafka\\libs\\scala-logging_2.11-3.9.0.jar;E:\\LogAnalysis\\kafka\\libs\\scala-reflect-2.11.12.jar;E:\\LogAnalysis\\kafka\\libs\\slf4j-api-1.7.26.jar;E:\\LogAnalysis\\kafka\\libs\\slf4j-log4j12-1.7.26.jar;E:\\LogAnalysis\\kafka\\libs\\snappy-java-1.1.7.3.jar;E:\\LogAnalysis\\kafka\\libs\\spotbugs-annotations-3.1.9.jar;E:\\LogAnalysis\\kafka\\libs\\validation-api-2.0.1.Final.jar;E:\\LogAnalysis\\kafka\\libs\\zkclient-0.11.jar;E:\\LogAnalysis\\kafka\\libs\\zookeeper-3.4.14.jar;E:\\LogAnalysis\\kafka\\libs\\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Server environment:java.library.path=C:\\Program Files\\Java\\jdk-17\\bin;C:\\Windows\\Sun\\Java\\bin;C:\\Windows\\system32;C:\\Windows;C:\\Program Files\\Common Files\\Oracle\\Java\\javapath;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Windows\\System32\\OpenSSH\\;C:\\Program Files\\Java\\jdk-14.0.2\\bin;C:\\Program Files\\Java\\jdk-14.0.2\\lib;E:\\LogAnalysis\\kafka\\bin\\windows;;. (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log   Server environment:java.io.tmpdir=C:\\Users\\Nagaraju\\AppData\\Local\\Temp\\ (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Server environment:user.name=Nagaraju (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Server environment:user.home=C:\\Users\\Nagaraju (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Processsing Log   Server environment:user.dir=C:\\Users\\Nagaraju (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 3 0 0 0 0 0 0 0 2\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
            "Processsing Log   tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)\n",
            "The currrent log streammed and clustered into group of  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Processsing Log   binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)\n",
            "The currrent log streammed and clustered into group of  [0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1008: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        }
      ]
    }
  ]
}